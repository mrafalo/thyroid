{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "import work\n",
    "import work.models as m\n",
    "import work.data as d\n",
    "import utils\n",
    "import utils.image_manipulator as im\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "import yaml    \n",
    "import logging\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "import wandb\n",
    "import copy\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "\n",
    "from keras.initializers import Constant\n",
    "from keras.layers import Input, Conv2D, Flatten, Activation, MaxPool2D, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dense, Conv2D,  MaxPool2D, Flatten, GlobalAveragePooling2D,  BatchNormalization, Layer, Add\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "\n",
    "import work.models as m\n",
    "import work.data as d\n",
    "\n",
    "\n",
    "with open(r'config.yaml') as file:\n",
    "    cfg = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    BASE_PATH = cfg['BASE_PATH']\n",
    "    IMG_WIDTH = cfg['IMG_WIDTH']\n",
    "    IMG_HEIGHT = cfg['IMG_HEIGHT']\n",
    "\n",
    "\n",
    "logger = logging.getLogger('main')\n",
    "logger.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter('%(asctime)s(%(name)s) %(levelname)s: %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "ch.setLevel(logging.DEBUG)\n",
    "if (logger.hasHandlers()):\n",
    "    logger.handlers.clear()\n",
    "  \n",
    "logger.addHandler(ch)\n",
    "\n",
    " \n",
    "BASE_FILE_PATH = BASE_PATH + 'baza5.csv'\n",
    "TRAIN_PATH = BASE_PATH + 'modeling/all_images/train/'\n",
    "VAL_PATH = BASE_PATH + 'modeling/all_images/validation/'\n",
    "TEST_PATH = BASE_PATH + 'modeling/all_images/test/'\n",
    "INPUT_PATH = BASE_PATH + 'modeling/all_images/'\n",
    "OUTPUT_TEST_PATH = TEST_PATH\n",
    "OUTPUT_TRAIN_PATH = TRAIN_PATH\n",
    "OUTPUT_VAL_PATH = VAL_PATH\n",
    "\n",
    "def model_cnn1(_img_width, _img_height):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(_img_height, _img_width, 1)))\n",
    "    model.add(Conv2D(8, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(12, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(16, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(24, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D((2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(48, (3, 3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(filters=1,kernel_size=(5, 5),kernel_initializer=\"glorot_normal\",bias_initializer=Constant(value=-0.9)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# def data():\n",
    "#     (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(X_train,    y_train, test_size=0.2, random_state=12345)\n",
    "#     X_train = X_train.reshape(48000, 784)\n",
    "#     X_val = X_val.reshape(12000, 784)\n",
    "#     X_train = X_train.astype('float32')\n",
    "#     X_val = X_val.astype('float32')\n",
    "#     X_train /= 255\n",
    "#     X_val /= 255\n",
    "#     nb_classes = 10\n",
    "#     Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "#     Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
    "#     return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "def model(X_train, Y_train, X_val, Y_val):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(180, 180, 1)))\n",
    "    model.add(Dense({{choice([128, 256, 512, 1024])}}, input_shape=(784,)))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([128, 256, 512, 1024])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    adam = keras.optimizers.Adam(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    rmsprop = keras.optimizers.RMSprop(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "    sgd = keras.optimizers.SGD(lr={{choice([10**-3, 10**-2, 10**-1])}})\n",
    "   \n",
    "    choiceval = {{choice(['adam', 'sgd', 'rmsprop'])}}\n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    elif choiceval == 'rmsprop':\n",
    "        optim = rmsprop\n",
    "    else:\n",
    "        optim = sgd\n",
    "        \n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size={{choice([128,256,512])}},\n",
    "              nb_epoch=20,\n",
    "              verbose=2,\n",
    "              validation_data=(X_val, Y_val))\n",
    "    score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
    "\n",
    "\n",
    "def data():\n",
    "    with open(r'config.yaml') as file:\n",
    "        cfg = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        BASE_PATH = cfg['BASE_PATH']\n",
    "        IMG_WIDTH = cfg['IMG_WIDTH']\n",
    "        IMG_HEIGHT = cfg['IMG_HEIGHT']\n",
    "    \n",
    "    BASE_FILE_PATH = BASE_PATH + 'baza5.csv'\n",
    "    TRAIN_PATH = BASE_PATH + 'modeling/all_images/train/'\n",
    "    VAL_PATH = BASE_PATH + 'modeling/all_images/validation/'\n",
    "    TEST_PATH = BASE_PATH + 'modeling/all_images/test/'\n",
    "    INPUT_PATH = BASE_PATH + 'modeling/all_images/'\n",
    "    OUTPUT_TEST_PATH = TEST_PATH\n",
    "    OUTPUT_TRAIN_PATH = TRAIN_PATH\n",
    "    OUTPUT_VAL_PATH = VAL_PATH\n",
    "\n",
    "    d.split_files(INPUT_PATH, OUTPUT_TRAIN_PATH, OUTPUT_VAL_PATH, OUTPUT_TEST_PATH, 0.15, 0.15)\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = d.split_data(BASE_FILE_PATH, OUTPUT_TRAIN_PATH, OUTPUT_VAL_PATH, OUTPUT_TEST_PATH, 0, 'none')\n",
    "    return X_train, y_train, X_val, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import cv2\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import importlib\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import work\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import work.models as m\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import work.data as d\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import utils.image_manipulator as im\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.optimizers import RMSprop, Adam\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import yaml\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import logging\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import keras\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from matplotlib import pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import random\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import wandb\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import copy\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from wandb.keras import WandbMetricsLogger\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.initializers import Constant\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Input, Conv2D, Flatten, Activation, MaxPool2D, Dropout\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Model\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import tensorflow as tf\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import backend as K\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.optimizers import RMSprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, GlobalAveragePooling2D, BatchNormalization, Layer, Add\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.optimizers import SGD\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import work.models as m\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import work.data as d\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dense': hp.choice('Dense', [128, 256, 512, 1024]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense_1': hp.choice('Dense_1', [128, 256, 512, 1024]),\n",
      "        'Activation_1': hp.choice('Activation_1', ['relu', 'sigmoid']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'lr': hp.choice('lr', [10**-3, 10**-2, 10**-1]),\n",
      "        'lr_1': hp.choice('lr_1', [10**-3, 10**-2, 10**-1]),\n",
      "        'lr_2': hp.choice('lr_2', [10**-3, 10**-2, 10**-1]),\n",
      "        'choiceval': hp.choice('choiceval', ['adam', 'sgd', 'rmsprop']),\n",
      "        'batch_size': hp.choice('batch_size', [128,256,512]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: d.split_files(INPUT_PATH, OUTPUT_TRAIN_PATH, OUTPUT_VAL_PATH, OUTPUT_TEST_PATH, 0.15, 0.15)\n",
      "  3: \n",
      "  4: X_train, y_train, X_val, y_val, X_test, y_test = d.split_data(BASE_FILE_PATH, OUTPUT_TRAIN_PATH, OUTPUT_VAL_PATH, OUTPUT_TEST_PATH, 0, 'none')\n",
      "  5: \n",
      "  6: \n",
      "  7: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     \n",
      "   4:     model = Sequential()\n",
      "   5:     model.add(Dense(space['Dense'], input_shape=(784,)))\n",
      "   6:     model.add(Activation(space['Activation']))\n",
      "   7:     model.add(Dropout(space['Dropout']))\n",
      "   8:     model.add(Dense(space['Dense_1']))\n",
      "   9:     model.add(Activation(space['Activation_1']))\n",
      "  10:     model.add(Dropout(space['Dropout_1']))\n",
      "  11:     \n",
      "  12:     model.add(Dense(10))\n",
      "  13:     model.add(Activation('softmax'))\n",
      "  14:     adam = keras.optimizers.Adam(lr=space['lr'])\n",
      "  15:     rmsprop = keras.optimizers.RMSprop(lr=space['lr_1'])\n",
      "  16:     sgd = keras.optimizers.SGD(lr=space['lr_2'])\n",
      "  17:    \n",
      "  18:     choiceval = space['choiceval']\n",
      "  19:     if choiceval == 'adam':\n",
      "  20:         optim = adam\n",
      "  21:     elif choiceval == 'rmsprop':\n",
      "  22:         optim = rmsprop\n",
      "  23:     else:\n",
      "  24:         optim = sgd\n",
      "  25:         \n",
      "  26:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
      "  27:     model.fit(X_train, Y_train,\n",
      "  28:               batch_size=space['batch_size'],\n",
      "  29:               nb_epoch=20,\n",
      "  30:               verbose=2,\n",
      "  31:               validation_data=(X_val, Y_val))\n",
      "  32:     score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
      "  33:     print('Test accuracy:', acc)\n",
      "  34:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  35: \n",
      "Unexpected error: <class 'NameError'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'INPUT_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-30c1481a40e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m best_run, best_model = optim.minimize(model=model,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                       \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                       \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space, keep_temp)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mreturn_space\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mpair\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \"\"\"\n\u001b[1;32m---> 59\u001b[1;33m     best_run, space = base_minimizer(model=model,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                      \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                                      \u001b[0mfunctions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack, keep_temp)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mtemp_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_fmin_fnct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_space\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unexpected error: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Google Drive\\dev\\py\\thyroid\\temp_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mINPUT_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_TRAIN_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_VAL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_TEST_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBASE_FILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_TRAIN_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_VAL_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOUTPUT_TEST_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'none'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'INPUT_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=30,\n",
    "                                      trials=Trials(),\n",
    "                                     notebook_name='sample')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
